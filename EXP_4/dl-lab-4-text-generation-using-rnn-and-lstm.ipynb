{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-26T09:46:58.040902Z",
     "iopub.status.busy": "2025-03-26T09:46:58.040645Z",
     "iopub.status.idle": "2025-03-26T09:47:01.517792Z",
     "shell.execute_reply": "2025-03-26T09:47:01.517156Z",
     "shell.execute_reply.started": "2025-03-26T09:46:58.040881Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T09:47:01.518989Z",
     "iopub.status.busy": "2025-03-26T09:47:01.518577Z",
     "iopub.status.idle": "2025-03-26T09:47:01.532313Z",
     "shell.execute_reply": "2025-03-26T09:47:01.530633Z",
     "shell.execute_reply.started": "2025-03-26T09:47:01.518959Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the Dataset\n",
    "text = \"\"\n",
    "with open(\"/kaggle/input/poems-dataset/poems-100.csv\", \"r\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        text += \" \".join(row) + \" \"                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-26T09:47:01.532770Z",
     "iopub.status.idle": "2025-03-26T09:47:01.533118Z",
     "shell.execute_reply": "2025-03-26T09:47:01.532944Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tokenize the Text into Words\n",
    "tokens = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-26T09:47:01.533803Z",
     "iopub.status.idle": "2025-03-26T09:47:01.534189Z",
     "shell.execute_reply": "2025-03-26T09:47:01.534006Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a Dictionary to Map Words to Indices\n",
    "word_to_idx = {}\n",
    "idx_to_word = {}\n",
    "vocab_size = 0\n",
    "\n",
    "for word in tokens:\n",
    "    if word not in word_to_idx:\n",
    "        word_to_idx[word] = vocab_size\n",
    "        idx_to_word[vocab_size] = word\n",
    "        vocab_size += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-26T09:47:01.535019Z",
     "iopub.status.idle": "2025-03-26T09:47:01.535410Z",
     "shell.execute_reply": "2025-03-26T09:47:01.535238Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert Tokens to Indices\n",
    "token_indices = [word_to_idx[word] for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-26T09:47:01.536373Z",
     "iopub.status.idle": "2025-03-26T09:47:01.536744Z",
     "shell.execute_reply": "2025-03-26T09:47:01.536576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Vocabulary Size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-26T09:47:01.537675Z",
     "iopub.status.idle": "2025-03-26T09:47:01.538034Z",
     "shell.execute_reply": "2025-03-26T09:47:01.537878Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create Sequences and Targets\n",
    "seq_length = 10\n",
    "sequences = []\n",
    "targets = []\n",
    "\n",
    "for i in range(len(token_indices) - seq_length):\n",
    "    seq = token_indices[i:i + seq_length]\n",
    "    target = token_indices[i + seq_length]\n",
    "    sequences.append(seq)\n",
    "    targets.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-26T09:47:01.538758Z",
     "iopub.status.idle": "2025-03-26T09:47:01.539133Z",
     "shell.execute_reply": "2025-03-26T09:47:01.538954Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert to PyTorch Tensors\n",
    "sequences = torch.tensor(sequences, dtype = torch.long)\n",
    "targets = torch.tensor(targets, dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-26T09:47:01.540409Z",
     "iopub.status.idle": "2025-03-26T09:47:01.540779Z",
     "shell.execute_reply": "2025-03-26T09:47:01.540617Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define One-Hot Encoding for RNN Model\n",
    "class OneHotRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim, output_dim):\n",
    "        super(OneHotRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(vocab_size, hidden_dim, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, _ = self.rnn(x)\n",
    "        out = self.fc(output[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-26T09:47:01.541436Z",
     "iopub.status.idle": "2025-03-26T09:47:01.541803Z",
     "shell.execute_reply": "2025-03-26T09:47:01.541646Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define LSTM Model with Embedding Layer\n",
    "class PoemLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super(PoemLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, _ = self.lstm(embedded)\n",
    "        out = self.fc(output[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-26T09:47:01.542722Z",
     "iopub.status.idle": "2025-03-26T09:47:01.543035Z",
     "shell.execute_reply": "2025-03-26T09:47:01.542921Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "embed_dim = 100\n",
    "hidden_dim = 128\n",
    "output_dim = vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-26T09:47:01.544198Z",
     "iopub.status.idle": "2025-03-26T09:47:01.544521Z",
     "shell.execute_reply": "2025-03-26T09:47:01.544360Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize Models\n",
    "onehot_model = OneHotRNN(vocab_size, hidden_dim, output_dim)\n",
    "embedding_model = PoemLSTM(vocab_size, embed_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-26T09:47:01.545199Z",
     "iopub.status.idle": "2025-03-26T09:47:01.545475Z",
     "shell.execute_reply": "2025-03-26T09:47:01.545363Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "onehot_optimizer = optim.Adam(onehot_model.parameters(), lr = 0.001)\n",
    "embedding_optimizer = optim.Adam(embedding_model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-26T09:47:01.546319Z",
     "iopub.status.idle": "2025-03-26T09:47:01.546636Z",
     "shell.execute_reply": "2025-03-26T09:47:01.546528Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loss Tracking\n",
    "onehot_losses, embedding_losses = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-26T09:47:01.547218Z",
     "iopub.status.idle": "2025-03-26T09:47:01.547505Z",
     "shell.execute_reply": "2025-03-26T09:47:01.547388Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training Function with Tracking\n",
    "def train_model(model, optimizer, name):\n",
    "    start_time = time.time()\n",
    "    for epoch in range(100):\n",
    "        total_loss = 0\n",
    "        for i in range(0, len(sequences), 32):\n",
    "            batch_seq = sequences[i:i + 32]\n",
    "            batch_target = targets[i:i + 32]\n",
    "\n",
    "            # One-Hot Encoding for OneHotRNN\n",
    "            if name == \"OneHotRNN\":\n",
    "                batch_seq = F.one_hot(batch_seq, num_classes = vocab_size).float()\n",
    "\n",
    "            # Forward Pass\n",
    "            outputs = model(batch_seq)\n",
    "            loss = criterion(outputs, batch_target)\n",
    "\n",
    "            # Backward Pass and Optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / (len(sequences) // 32)\n",
    "        if name == \"OneHotRNN\":\n",
    "            onehot_losses.append(avg_loss)\n",
    "        else:\n",
    "            embedding_losses.append(avg_loss)\n",
    "\n",
    "        print(f\"{name} Epoch [{epoch+1}/100], Avg Loss: {avg_loss:.4f}\")\n",
    "    print(f\"{name} Training Time: {time.time() - start_time:.2f}s\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-26T09:47:01.548036Z",
     "iopub.status.idle": "2025-03-26T09:47:01.548339Z",
     "shell.execute_reply": "2025-03-26T09:47:01.548237Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Poem Generation Function\n",
    "def generate_poem(model, seed_text, num_words = 50, model_type = \"EmbeddingLSTM\"):\n",
    "    model.eval()\n",
    "    words = seed_text.split()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_words):\n",
    "            seq = [word_to_idx.get(word, 0) for word in words[-seq_length:]]\n",
    "            seq = torch.tensor(seq, dtype = torch.long).unsqueeze(0)\n",
    "\n",
    "            if model_type == \"OneHotRNN\":\n",
    "                seq = F.one_hot(seq, num_classes = vocab_size).float()\n",
    "\n",
    "            output = model(seq)\n",
    "            probabilities = F.softmax(output, dim = 1)\n",
    "            predicted_idx = torch.multinomial(probabilities, 1).item()\n",
    "\n",
    "            words.append(idx_to_word[predicted_idx])\n",
    "\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-26T09:47:01.548882Z",
     "iopub.status.idle": "2025-03-26T09:47:01.549148Z",
     "shell.execute_reply": "2025-03-26T09:47:01.549014Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train Models\n",
    "train_model(onehot_model, onehot_optimizer, \"OneHotRNN\")\n",
    "train_model(embedding_model, embedding_optimizer, \"EmbeddingLSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-26T09:47:01.549745Z",
     "iopub.status.idle": "2025-03-26T09:47:01.549971Z",
     "shell.execute_reply": "2025-03-26T09:47:01.549880Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Generate Poems\n",
    "seed_text = \"I wandered lonely as a\"\n",
    "print(\"\\nGenerated Poem (OneHotRNN):\", generate_poem(onehot_model, seed_text, model_type = \"OneHotRNN\"))\n",
    "print(\"\\nGenerated Poem (EmbeddingLSTM):\", generate_poem(embedding_model, seed_text, model_type = \"EmbeddingLSTM\"))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6623322,
     "sourceId": 10689716,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
